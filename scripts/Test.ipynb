{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas datasets pyarrow psycopg2 sqlalchemy boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: swifter in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.4.0)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from swifter) (2.2.3)\n",
      "Requirement already satisfied: psutil>=5.6.6 in /Users/estefanyaguilar/Library/Python/3.13/lib/python/site-packages (from swifter) (7.0.0)\n",
      "Requirement already satisfied: dask>=2.10.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[dataframe]>=2.10.0->swifter) (2025.2.0)\n",
      "Requirement already satisfied: tqdm>=4.33.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from swifter) (4.67.1)\n",
      "Requirement already satisfied: click>=8.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (8.1.8)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (3.1.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/estefanyaguilar/Library/Python/3.13/lib/python/site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (24.2)\n",
      "Requirement already satisfied: partd>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (1.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (6.0.2)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (1.0.0)\n",
      "Requirement already satisfied: pyarrow>=14.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[dataframe]>=2.10.0->swifter) (19.0.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas>=1.0.0->swifter) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/estefanyaguilar/Library/Python/3.13/lib/python/site-packages (from pandas>=1.0.0->swifter) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas>=1.0.0->swifter) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas>=1.0.0->swifter) (2025.1)\n",
      "Requirement already satisfied: locket in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from partd>=1.4.0->dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/estefanyaguilar/Library/Python/3.13/lib/python/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->swifter) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "import swifter\n",
    "import psycopg2\n",
    "from tqdm import tqdm\n",
    "import io\n",
    "import json\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_access_key=\"AKIAWT3FL27M2NQ3LSTG\"\n",
    "aws_secret_key=\"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\"\n",
    "region_name=\"us-east-2\"\n",
    "url_dataset=\"Qdrant/wolt-food-clip-ViT-B-32-embeddings\"\n",
    "bucket_name = \"software-engineer-interview-test-bucket-1\"\n",
    "folder_s3=\"images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Cargar el dataset desde Hugging Face\n",
    "dataset = load_dataset(url_dataset)\n",
    "# Mostrar algunas muestras del dataset\n",
    "\n",
    "print(dataset)\n",
    "print(dataset[\"train\"][0])  # Muestra la primera entrada del conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dataset[\"train\"][:5])  # Muestra las primeras 5 entradas del conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (AccessDenied) when calling the ListBuckets operation: User: arn:aws:iam::454942250969:user/engineer-project-presentation-1 is not authorized to perform: s3:ListAllMyBuckets because no identity-based policy allows the s3:ListAllMyBuckets action",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m s3 = boto3.client(\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33ms3\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     aws_access_key_id=aws_access_key,\n\u001b[32m      4\u001b[39m     aws_secret_access_key=aws_secret_key,\n\u001b[32m      5\u001b[39m     region_name=region_name  \u001b[38;5;66;03m# Cambia segÃºn tu regiÃ³n\u001b[39;00m\n\u001b[32m      6\u001b[39m )\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Listar los buckets para verificar que la conexiÃ³n funciona\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m response = \u001b[43ms3\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlist_buckets\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m bucket \u001b[38;5;129;01min\u001b[39;00m response[\u001b[33m\"\u001b[39m\u001b[33mBuckets\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mprint\u001b[39m(bucket[\u001b[33m\"\u001b[39m\u001b[33mName\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/botocore/client.py:570\u001b[39m, in \u001b[36mClientCreator._create_api_method.<locals>._api_call\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    566\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    567\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m() only accepts keyword arguments.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    568\u001b[39m     )\n\u001b[32m    569\u001b[39m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/botocore/context.py:124\u001b[39m, in \u001b[36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[32m    123\u001b[39m     hook()\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/botocore/client.py:1031\u001b[39m, in \u001b[36mBaseClient._make_api_call\u001b[39m\u001b[34m(self, operation_name, api_params)\u001b[39m\n\u001b[32m   1027\u001b[39m     error_code = error_info.get(\u001b[33m\"\u001b[39m\u001b[33mQueryErrorCode\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info.get(\n\u001b[32m   1028\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCode\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1029\u001b[39m     )\n\u001b[32m   1030\u001b[39m     error_class = \u001b[38;5;28mself\u001b[39m.exceptions.from_code(error_code)\n\u001b[32m-> \u001b[39m\u001b[32m1031\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[32m   1032\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1033\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[31mClientError\u001b[39m: An error occurred (AccessDenied) when calling the ListBuckets operation: User: arn:aws:iam::454942250969:user/engineer-project-presentation-1 is not authorized to perform: s3:ListAllMyBuckets because no identity-based policy allows the s3:ListAllMyBuckets action"
     ]
    }
   ],
   "source": [
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    aws_access_key_id=aws_access_key,\n",
    "    aws_secret_access_key=aws_secret_key,\n",
    "    region_name=region_name  # Cambia segÃºn tu regiÃ³n\n",
    ")\n",
    "\n",
    "# Listar los buckets para verificar que la conexiÃ³n funciona\n",
    "response = s3.list_buckets()\n",
    "for bucket in response[\"Buckets\"]:\n",
    "    print(bucket[\"Name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dataset[\"train\"][:5]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a DataFrame de pandas\n",
    "df = pd.DataFrame(dataset[\"train\"][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"cafe\"] = df[\"cafe\"].apply(lambda x: x.decode(\"utf-8\") if isinstance(x, bytes) else x)\n",
    "#df[\"vector\"] = df[\"vector\"].apply(lambda x: x.decode(\"utf-8\") if isinstance(x, bytes) else x)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cafe\"] = df[\"cafe\"].apply(lambda x: x.decode(\"utf-8\") if isinstance(x, bytes) else x).apply(json.loads)\n",
    "df[\"vector\"] = df[\"vector\"].apply(lambda x: x.decode(\"utf-8\") if isinstance(x, bytes) else x).apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir tamaÃ±o de cada chunk\n",
    "chunk_size = 50_000\n",
    "\n",
    "# Dividir el DataFrame en chunks y subirlos a S3\n",
    "for i, chunk in enumerate(range(0, len(df), chunk_size)):\n",
    "    df_chunk = df.iloc[chunk:chunk + chunk_size]  # Obtener el chunk\n",
    "    file_name = f\"wolt_food_part_{i+1}.parquet\"  # Nombre del archivo\n",
    "\n",
    "    # Guardar como Parquet temporalmente\n",
    "    df_chunk.to_parquet(file_name, engine=\"pyarrow\")\n",
    "\n",
    "    # Subir a S3\n",
    "    s3.upload_file(file_name, bucket_name, f\"{folder_s3}/{file_name}\")\n",
    "    print(f\"Subido {file_name} a s3://{bucket_name}/{folder_s3}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¹ 1. Configurar conexiÃ³n a PostgreSQL\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"postgres\",\n",
    "    user=\"snappr\",  # Usuario extraÃ­do de la URL\n",
    "    password=\"OYeTFSsi4LLZ4qlGwR14\",  # ContraseÃ±a extraÃ­da de la URL\n",
    "    host=\"software-engineer-interview-test-db-1.cluster-ccf5q9owrldj.us-east-2.rds.amazonaws.com\",\n",
    "    port=\"5432\"  # PostgreSQL usa el puerto 5432 por defecto\n",
    ")\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Key': 'images/images_1.parquet', 'LastModified': datetime.datetime(2025, 3, 7, 23, 4, 25, tzinfo=tzutc()), 'ETag': '\"991571cfd8c10b67c48118dd4f7976bd-19\"', 'ChecksumAlgorithm': ['CRC32'], 'ChecksumType': 'COMPOSITE', 'Size': 156570385, 'StorageClass': 'STANDARD'}, {'Key': 'images/images_10.parquet', 'LastModified': datetime.datetime(2025, 3, 7, 23, 5, 40, tzinfo=tzutc()), 'ETag': '\"affd7b39a7f54770b014fe5efd75ba3a-19\"', 'ChecksumAlgorithm': ['CRC32'], 'ChecksumType': 'COMPOSITE', 'Size': 155520708, 'StorageClass': 'STANDARD'}, {'Key': 'images/images_2.parquet', 'LastModified': datetime.datetime(2025, 3, 7, 23, 4, 39, tzinfo=tzutc()), 'ETag': '\"77ff6686f6b9904e3cad43970c4d9602-19\"', 'ChecksumAlgorithm': ['CRC32'], 'ChecksumType': 'COMPOSITE', 'Size': 156738474, 'StorageClass': 'STANDARD'}, {'Key': 'images/images_3.parquet', 'LastModified': datetime.datetime(2025, 3, 7, 23, 4, 47, tzinfo=tzutc()), 'ETag': '\"0ac7dc4f1adce4eb1b7b771ae179b44d-19\"', 'ChecksumAlgorithm': ['CRC32'], 'ChecksumType': 'COMPOSITE', 'Size': 156692878, 'StorageClass': 'STANDARD'}, {'Key': 'images/images_4.parquet', 'LastModified': datetime.datetime(2025, 3, 7, 23, 4, 56, tzinfo=tzutc()), 'ETag': '\"ab28d38611ef036b770376a7a3669c22-19\"', 'ChecksumAlgorithm': ['CRC32'], 'ChecksumType': 'COMPOSITE', 'Size': 155986790, 'StorageClass': 'STANDARD'}, {'Key': 'images/images_5.parquet', 'LastModified': datetime.datetime(2025, 3, 7, 23, 5, 4, tzinfo=tzutc()), 'ETag': '\"74faee3a37b9586439e47d75e3055f52-19\"', 'ChecksumAlgorithm': ['CRC32'], 'ChecksumType': 'COMPOSITE', 'Size': 156146408, 'StorageClass': 'STANDARD'}, {'Key': 'images/images_6.parquet', 'LastModified': datetime.datetime(2025, 3, 7, 23, 5, 11, tzinfo=tzutc()), 'ETag': '\"45b810ccb238c5c0e88da2e37232c1bd-19\"', 'ChecksumAlgorithm': ['CRC32'], 'ChecksumType': 'COMPOSITE', 'Size': 156322232, 'StorageClass': 'STANDARD'}, {'Key': 'images/images_7.parquet', 'LastModified': datetime.datetime(2025, 3, 7, 23, 5, 20, tzinfo=tzutc()), 'ETag': '\"5ece5d9c6f33b75f40d0ecbebda58edc-19\"', 'ChecksumAlgorithm': ['CRC32'], 'ChecksumType': 'COMPOSITE', 'Size': 156513589, 'StorageClass': 'STANDARD'}, {'Key': 'images/images_8.parquet', 'LastModified': datetime.datetime(2025, 3, 7, 23, 5, 27, tzinfo=tzutc()), 'ETag': '\"f601ed3a2bce6b7cb2739a35e62536f8-19\"', 'ChecksumAlgorithm': ['CRC32'], 'ChecksumType': 'COMPOSITE', 'Size': 156436665, 'StorageClass': 'STANDARD'}, {'Key': 'images/images_9.parquet', 'LastModified': datetime.datetime(2025, 3, 7, 23, 5, 33, tzinfo=tzutc()), 'ETag': '\"42d05ed6300a4c488ea51c83a3c52a4d-19\"', 'ChecksumAlgorithm': ['CRC32'], 'ChecksumType': 'COMPOSITE', 'Size': 156881172, 'StorageClass': 'STANDARD'}, {'Key': 'images/wolt_food_part_1.parquet', 'LastModified': datetime.datetime(2025, 3, 7, 20, 27, 58, tzinfo=tzutc()), 'ETag': '\"a177f62c6ec4229ef280875297098d80\"', 'ChecksumAlgorithm': ['CRC32'], 'ChecksumType': 'FULL_OBJECT', 'Size': 1809470, 'StorageClass': 'STANDARD'}]\n"
     ]
    }
   ],
   "source": [
    "# ðŸ”¹ Obtener la lista de archivos en la carpeta\n",
    "response = s3.list_objects_v2(Bucket=bucket_name, Prefix=folder_s3)\n",
    "print( response.get(\"Contents\", []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['images/images_1.parquet', 'images/images_10.parquet', 'images/images_2.parquet', 'images/images_3.parquet', 'images/images_4.parquet', 'images/images_5.parquet', 'images/images_6.parquet', 'images/images_7.parquet', 'images/images_8.parquet', 'images/images_9.parquet', 'images/wolt_food_part_1.parquet']\n"
     ]
    }
   ],
   "source": [
    "file_keys= [obj[\"Key\"] for obj in response.get(\"Contents\", []) if obj[\"Key\"].endswith((\".parquet\", \".csv\"))]\n",
    "print(file_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Descargando archivos:   0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/images_1.parquet\n",
      "<_io.BytesIO object at 0x15eab9c60>\n",
      "Index(['id', 'cafe', 'description', 'image', 'image_file', 'name', 'vector'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:00<00:00, 114582.50it/s]\n",
      "Pandas Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:00<00:00, 122870.62it/s]\n",
      "Descargando archivos:   9%|â–‰         | 1/11 [04:24<44:07, 264.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/images_10.parquet\n",
      "<_io.BytesIO object at 0x2e8bef6a0>\n",
      "Index(['id', 'cafe', 'description', 'image', 'image_file', 'name', 'vector'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:00<00:00, 63669.78it/s] \n",
      "Pandas Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:00<00:00, 2570795.33it/s]\n",
      "Descargando archivos:  18%|â–ˆâ–Š        | 2/11 [06:45<28:45, 191.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/images_2.parquet\n",
      "<_io.BytesIO object at 0x2f87545e0>\n",
      "Index(['id', 'cafe', 'description', 'image', 'image_file', 'name', 'vector'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:00<00:00, 113064.80it/s]\n",
      "Pandas Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:00<00:00, 2479430.61it/s]\n",
      "Descargando archivos:  27%|â–ˆâ–ˆâ–‹       | 3/11 [10:03<25:56, 194.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/images_3.parquet\n",
      "<_io.BytesIO object at 0x17c354cc0>\n",
      "Index(['id', 'cafe', 'description', 'image', 'image_file', 'name', 'vector'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:00<00:00, 105496.54it/s]\n",
      "Pandas Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:00<00:00, 2567930.74it/s]\n",
      "Descargando archivos:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 4/11 [12:26<20:20, 174.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/images_4.parquet\n",
      "<_io.BytesIO object at 0x150b150d0>\n",
      "Index(['id', 'cafe', 'description', 'image', 'image_file', 'name', 'vector'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:00<00:00, 110863.29it/s]\n",
      "Pandas Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:00<00:00, 2490797.66it/s]\n",
      "Descargando archivos:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 5/11 [15:30<17:45, 177.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/images_5.parquet\n",
      "<_io.BytesIO object at 0x150b14e00>\n",
      "Index(['id', 'cafe', 'description', 'image', 'image_file', 'name', 'vector'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:00<00:00, 102572.09it/s]\n",
      "Pandas Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:00<00:00, 2515747.17it/s]\n",
      "Descargando archivos:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 6/11 [17:47<13:39, 163.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/images_6.parquet\n",
      "<_io.BytesIO object at 0x2e7e84400>\n",
      "Index(['id', 'cafe', 'description', 'image', 'image_file', 'name', 'vector'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:00<00:00, 108266.37it/s]\n",
      "Pandas Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:00<00:00, 2536805.82it/s]\n",
      "Descargando archivos:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 7/11 [20:13<10:32, 158.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/images_7.parquet\n",
      "<_io.BytesIO object at 0x2f7d81940>\n",
      "Index(['id', 'cafe', 'description', 'image', 'image_file', 'name', 'vector'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:00<00:00, 114609.81it/s]\n",
      "Pandas Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:00<00:00, 2540124.27it/s]\n",
      "Descargando archivos:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 8/11 [22:25<07:29, 149.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/images_8.parquet\n",
      "<_io.BytesIO object at 0x3419e98f0>\n",
      "Index(['id', 'cafe', 'description', 'image', 'image_file', 'name', 'vector'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:00<00:00, 107214.93it/s]\n",
      "Pandas Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:00<00:00, 2565825.73it/s]\n",
      "Descargando archivos:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 9/11 [24:57<05:00, 150.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/images_9.parquet\n",
      "<_io.BytesIO object at 0x2f69bf420>\n",
      "Index(['id', 'cafe', 'description', 'image', 'image_file', 'name', 'vector'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:00<00:00, 112333.57it/s]\n",
      "Pandas Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:00<00:00, 2513094.23it/s]\n",
      "Descargando archivos:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 10/11 [27:11<02:25, 145.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/wolt_food_part_1.parquet\n",
      "<_io.BytesIO object at 0x2f83913f0>\n",
      "Index(['id', 'cafe', 'description', 'image', 'image_file', 'name', 'vector'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 214608.27it/s]\n",
      "Pandas Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 1677721.60it/s]\n",
      "Descargando archivos:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 10/11 [27:13<02:43, 163.31s/it]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['location'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mvector\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m\"\u001b[39m\u001b[33mvector\u001b[39m\u001b[33m\"\u001b[39m].swifter.apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x.tolist() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, np.ndarray) \u001b[38;5;28;01melse\u001b[39;00m x)\n\u001b[32m     18\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mcategories\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m\"\u001b[39m\u001b[33mcategories\u001b[39m\u001b[33m\"\u001b[39m].swifter.apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x.tolist() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, np.ndarray) \u001b[38;5;28;01melse\u001b[39;00m x)   \n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m df = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcafe\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlocation\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m df.columns = [column.replace(\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m df.columns] \n\u001b[32m     23\u001b[39m df.to_sql(\u001b[33m\"\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m\"\u001b[39m, engine, if_exists=\u001b[33m\"\u001b[39m\u001b[33mappend\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/frame.py:5581\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5433\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5434\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5435\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5442\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5443\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5444\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5445\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5446\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5579\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5580\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5581\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5582\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5583\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5584\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5585\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5586\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5587\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5588\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5589\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/generic.py:4788\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4786\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4787\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4788\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4790\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4791\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/generic.py:4830\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4828\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4829\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4830\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4831\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4833\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4834\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/indexes/base.py:7070\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7068\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7069\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7070\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7071\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
      "\u001b[31mKeyError\u001b[39m: \"['location'] not found in axis\""
     ]
    }
   ],
   "source": [
    "for file_key in tqdm(file_keys, desc=\"Descargando archivos\"):\n",
    "    print(file_key)\n",
    "    # ðŸ”¹ Descargar archivo desde S3 a memoria\n",
    "    obj = s3.get_object(Bucket=bucket_name, Key=file_key)\n",
    "    file_stream = io.BytesIO(obj[\"Body\"].read())\n",
    "    print(file_stream)\n",
    "\n",
    "    df = pd.read_parquet(file_stream)\n",
    "    print(df.columns)\n",
    "\n",
    "    #df[\"cafe\"] = df[\"cafe\"].swifter.apply(lambda x: json.dumps(x) if isinstance(x, dict) else \"{}\")\n",
    "    json_aplanado = pd.json_normalize(df['cafe'], meta_prefix='cafe__')\n",
    "    json_aplanado.head()\n",
    "\n",
    "    df = df.join(json_aplanado, rsuffix=\"_cafe\")\n",
    "\n",
    "    df['vector'] = df[\"vector\"].swifter.apply(lambda x: x.tolist() if isinstance(x, np.ndarray) else x)\n",
    "    df['categories'] = df[\"categories\"].swifter.apply(lambda x: x.tolist() if isinstance(x, np.ndarray) else x)   \n",
    "    \n",
    "    df = df.drop(columns=['cafe','location'])\n",
    "    df.columns = [column.replace('.', '_') for column in df.columns] \n",
    "\n",
    "    df.to_sql(\"images\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_query = \"\"\" \\\n",
    "CREATE TABLE IF NOT EXISTS images (\n",
    "\tID INTEGER\n",
    "\t,CAFE JSONB  \n",
    "\t,DESCRIPTION VARCHAR\n",
    "\t,IMAGE VARCHAR\n",
    "\t,IMAGE_FILE VARCHAR\n",
    "\t,\"NAME\" VARCHAR\n",
    "\t,VECTOR JSONB\n",
    "\t,ADDRESS VARCHAR \n",
    "\t,CATEGORIES VARCHAR\n",
    "\t,MENU_ID VARCHAR\n",
    "\t,NAME_CAFE VARCHAR\n",
    "\t,RATING NUMERIC\n",
    "\t,SLUG VARCHAR\n",
    "\t,\"LOCATION.LAT\" NUMERIC  \n",
    "\t,\"LOCATION.LON\" NUMERIC\n",
    ") \\\n",
    "\"\"\".replace(\"\\n\\t\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{create_table_query}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pa.Table.from_pandas(df)\n",
    "\n",
    "# ðŸ”¹ Guardar en PostgreSQL\n",
    "pq.write_table(table, f\"{file_name}.parquet\")\n",
    "cursor.execute(\"BEGIN\")\n",
    "#cursor.execute(f\"{create_table_query}\")\n",
    "#cursor.execute(f\"COPY wolt_food FROM '{file_name}.parquet' (FORMAT PARQUET)\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(f\"{create_table_query}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df['vector'] = df[\"vector\"].apply(lambda x: x.tolist() if isinstance(x, np.ndarray) else x)\n",
    "df['categories'] = df[\"categories\"].apply(lambda x: x.tolist() if isinstance(x, np.ndarray) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [column.replace('.', '_') for column in df.columns]\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "usuario = \"snappr\"\n",
    "clave = \"OYeTFSsi4LLZ4qlGwR14\"\n",
    "host = \"software-engineer-interview-test-db-1.cluster-ccf5q9owrldj.us-east-2.rds.amazonaws.com\"\n",
    "puerto = \"5432\"\n",
    "db_nombre = \"postgres\"\n",
    "\n",
    "engine = create_engine(f\"postgresql+psycopg2://{usuario}:{clave}@{host}:{puerto}/{db_nombre}\")\n",
    "#df.to_sql(\"images\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in response.get(\"Contents\", []):\n",
    "    file_name = file[\"Key\"]\n",
    "    print(f\"Descargando {file_name}\")\n",
    "    #s3.download_file(bucket_name, file_name, file_name)\n",
    "    s3.get_object(Bucket=BUCKET_NAME, Key=file_key)\n",
    "\n",
    "    # ðŸ”¹ Leer el archivo Parquet\n",
    "    df = pd.read_parquet(file_name)\n",
    "\n",
    "    # ðŸ”¹ Convertir a tabla de PyArrow\n",
    "    table = pa.Table.from_pandas(df)\n",
    "\n",
    "    # ðŸ”¹ Guardar en PostgreSQL\n",
    "    pq.write_table(table, f\"{file_name}.parquet\")\n",
    "    cursor.execute(f\"{create_table_query}\")\n",
    "    cursor.execute(f\"COPY wolt_food FROM '{file_name}.parquet' (FORMAT PARQUET)\")\n",
    "    conn.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
